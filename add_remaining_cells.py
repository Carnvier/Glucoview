#!/usr/bin/env python3
"""
Script to add remaining cells to the diabetic retinopathy detection notebook
"""

import json

def create_cell(cell_type, source, metadata=None):
    """Create a notebook cell"""
    cell = {
        "cell_type": cell_type,
        "metadata": metadata or {},
        "source": source if isinstance(source, list) else [source]
    }
    
    if cell_type == "code":
        cell["execution_count"] = None
        cell["outputs"] = []
    
    return cell

# Load existing notebook
with open('/workspace/diabetic_retinopathy_detection.ipynb', 'r') as f:
    notebook = json.load(f)

# Additional cells to add
additional_cells = []

# Data loaders with weighted sampling
additional_cells.append(create_cell("code", [
    "# Create weighted sampler for handling class imbalance\n",
    "def create_weighted_sampler(dataset, labels):\n",
    "    \"\"\"Create weighted sampler for imbalanced dataset\"\"\"\n",
    "    class_counts = np.bincount(labels)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    sample_weights = [class_weights[label] for label in labels]\n",
    "    \n",
    "    return WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "# Create weighted sampler for training\n",
    "train_sampler = create_weighted_sampler(train_dataset, train_df['label_clean'].values)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    sampler=train_sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Data loaders created:\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Test data loading\n",
    "print(\"\\nTesting data loading...\")\n",
    "try:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    images, labels = sample_batch\n",
    "    print(f\"Batch shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Image range: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "    print(f\"Sample labels: {labels[:10].tolist()}\")\n",
    "    print(\"‚úÖ Data loading successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data loading error: {e}\")\n",
    "    print(\"Note: This is expected if no images are available.\")"
]))

# Model architecture
additional_cells.append(create_cell("markdown", [
    "## 3Ô∏è‚É£ Model Architecture (ResNet50)\n",
    "\n",
    "We'll use a two-phase training approach:\n",
    "1. **Phase 1**: Freeze backbone, train classifier head only\n",
    "2. **Phase 2**: Unfreeze backbone, fine-tune with smaller learning rate"
]))

additional_cells.append(create_cell("code", [
    "class DiabeticRetinopathyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, model_name='resnet50', pretrained=True):\n",
    "        super(DiabeticRetinopathyModel, self).__init__()\n",
    "        \n",
    "        # Load pretrained model\n",
    "        if model_name == 'resnet50':\n",
    "            self.backbone = models.resnet50(pretrained=pretrained)\n",
    "            num_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()  # Remove final layer\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "        \n",
    "        # Custom classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Classify\n",
    "        output = self.classifier(features)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def freeze_backbone(self):\n",
    "        \"\"\"Freeze backbone parameters\"\"\"\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_backbone(self):\n",
    "        \"\"\"Unfreeze backbone parameters\"\"\"\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def get_trainable_params(self):\n",
    "        \"\"\"Get number of trainable parameters\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "# Create model\n",
    "model = DiabeticRetinopathyModel(\n",
    "    num_classes=CONFIG['NUM_CLASSES'],\n",
    "    model_name=CONFIG['MODEL_NAME'],\n",
    "    pretrained=True\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model created: {CONFIG['MODEL_NAME']}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {model.get_trainable_params():,}\")\n",
    "\n",
    "# Test model forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    dummy_input = torch.randn(2, 3, CONFIG['IMAGE_SIZE'], CONFIG['IMAGE_SIZE']).to(device)\n",
    "    dummy_output = model(dummy_input)\n",
    "    print(f\"\\nModel output shape: {dummy_output.shape}\")\n",
    "    print(f\"Output range: [{dummy_output.min():.3f}, {dummy_output.max():.3f}]\")\n",
    "    print(\"‚úÖ Model forward pass successful!\")"
]))

# Training utilities
additional_cells.append(create_cell("code", [
    "# Training utilities\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.001, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "    \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        \n",
    "        if self.counter >= self.patience:\n",
    "            if self.restore_best_weights:\n",
    "                model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        self.best_weights = model.state_dict().copy()\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_prob=None):\n",
    "    \"\"\"Calculate comprehensive metrics\"\"\"\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, precision_recall_fscore_support,\n",
    "        roc_auc_score, confusion_matrix\n",
    "    )\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    \n",
    "    # Calculate AUC if probabilities provided\n",
    "    if y_prob is not None:\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_true, y_prob, multi_class='ovr', average='weighted')\n",
    "            metrics['auc'] = auc_score\n",
    "        except:\n",
    "            metrics['auc'] = 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Get predictions\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    metrics = calculate_metrics(all_labels, all_preds, all_probs)\n",
    "    \n",
    "    return epoch_loss, metrics\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    metrics = calculate_metrics(all_labels, all_preds, all_probs)\n",
    "    \n",
    "    return epoch_loss, metrics, all_labels, all_preds, all_probs\n",
    "\n",
    "print(\"Training utilities defined successfully!\")"
]))

# Phase 1 training
additional_cells.append(create_cell("markdown", [
    "### üéØ Phase 1: Train Classifier Head (Frozen Backbone)\n",
    "\n",
    "First, we'll freeze the ResNet50 backbone and train only the classifier head."
]))

additional_cells.append(create_cell("code", [
    "# Phase 1: Freeze backbone and train classifier\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 1: Training Classifier Head (Frozen Backbone)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Freeze backbone\n",
    "model.freeze_backbone()\n",
    "print(f\"Trainable parameters: {model.get_trainable_params():,}\")\n",
    "\n",
    "# Setup training\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CONFIG['LEARNING_RATE'], weight_decay=CONFIG['WEIGHT_DECAY'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "early_stopping = EarlyStopping(patience=CONFIG['PATIENCE'], min_delta=CONFIG['MIN_DELTA'])\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_acc': [], 'val_acc': [],\n",
    "    'train_f1': [], 'val_f1': [],\n",
    "    'val_auc': []\n",
    "}\n",
    "\n",
    "print(f\"\\nStarting Phase 1 training for up to {CONFIG['NUM_EPOCHS']} epochs...\")\n",
    "print(f\"Learning rate: {CONFIG['LEARNING_RATE']}\")\n",
    "print(f\"Batch size: {CONFIG['BATCH_SIZE']}\")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "phase1_epochs = 0\n",
    "\n",
    "for epoch in range(CONFIG['NUM_EPOCHS']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{CONFIG['NUM_EPOCHS']}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_metrics, _, _, _ = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_metrics['accuracy'])\n",
    "    history['val_acc'].append(val_metrics['accuracy'])\n",
    "    history['train_f1'].append(train_metrics['f1'])\n",
    "    history['val_f1'].append(val_metrics['f1'])\n",
    "    history['val_auc'].append(val_metrics.get('auc', 0.0))\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_metrics['accuracy']:.4f} | Train F1: {train_metrics['f1']:.4f}\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_metrics['accuracy']:.4f} | Val F1:   {val_metrics['f1']:.4f} | Val AUC: {val_metrics.get('auc', 0.0):.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if early_stopping(val_loss, model):\n",
    "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_metrics': val_metrics\n",
    "        }, os.path.join(CONFIG['SAVE_PATH'], 'best_phase1_model.pth'))\n",
    "        print(f\"‚úÖ Best model saved (Val Loss: {val_loss:.4f})\")\n",
    "    \n",
    "    phase1_epochs = epoch + 1\n",
    "\n",
    "print(f\"\\nPhase 1 completed after {phase1_epochs} epochs\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
]))

# Phase 2 training
additional_cells.append(create_cell("markdown", [
    "### üî• Phase 2: Fine-tune Entire Model (Unfrozen Backbone)\n",
    "\n",
    "Now we'll unfreeze the backbone and fine-tune the entire model with a smaller learning rate."
]))

additional_cells.append(create_cell("code", [
    "# Phase 2: Unfreeze and fine-tune entire model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHASE 2: Fine-tuning Entire Model (Unfrozen Backbone)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Unfreeze backbone\n",
    "model.unfreeze_backbone()\n",
    "print(f\"Trainable parameters: {model.get_trainable_params():,}\")\n",
    "\n",
    "# Setup training with smaller learning rate\n",
    "fine_tune_lr = CONFIG['LEARNING_RATE'] / 10  # 10x smaller LR for fine-tuning\n",
    "optimizer = optim.AdamW(model.parameters(), lr=fine_tune_lr, weight_decay=CONFIG['WEIGHT_DECAY'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "early_stopping = EarlyStopping(patience=CONFIG['PATIENCE']//2, min_delta=CONFIG['MIN_DELTA']/2)  # More sensitive\n",
    "\n",
    "print(f\"\\nStarting Phase 2 training for up to {CONFIG['NUM_EPOCHS']//2} epochs...\")\n",
    "print(f\"Fine-tuning learning rate: {fine_tune_lr}\")\n",
    "\n",
    "phase2_epochs = 0\n",
    "best_val_loss_phase2 = float('inf')\n",
    "\n",
    "for epoch in range(CONFIG['NUM_EPOCHS']//2):  # Fewer epochs for fine-tuning\n",
    "    print(f\"\\nPhase 2 - Epoch {epoch+1}/{CONFIG['NUM_EPOCHS']//2}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_metrics, _, _, _ = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_metrics['accuracy'])\n",
    "    history['val_acc'].append(val_metrics['accuracy'])\n",
    "    history['train_f1'].append(train_metrics['f1'])\n",
    "    history['val_f1'].append(val_metrics['f1'])\n",
    "    history['val_auc'].append(val_metrics.get('auc', 0.0))\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_metrics['accuracy']:.4f} | Train F1: {train_metrics['f1']:.4f}\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_metrics['accuracy']:.4f} | Val F1:   {val_metrics['f1']:.4f} | Val AUC: {val_metrics.get('auc', 0.0):.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if early_stopping(val_loss, model):\n",
    "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss_phase2:\n",
    "        best_val_loss_phase2 = val_loss\n",
    "        torch.save({\n",
    "            'epoch': phase1_epochs + epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_metrics': val_metrics,\n",
    "            'history': history\n",
    "        }, os.path.join(CONFIG['SAVE_PATH'], 'best_final_model.pth'))\n",
    "        print(f\"‚úÖ Best final model saved (Val Loss: {val_loss:.4f})\")\n",
    "    \n",
    "    phase2_epochs = epoch + 1\n",
    "\n",
    "print(f\"\\nPhase 2 completed after {phase2_epochs} epochs\")\n",
    "print(f\"Best validation loss: {best_val_loss_phase2:.4f}\")\n",
    "print(f\"\\nTotal training epochs: {phase1_epochs + phase2_epochs}\")"
]))

# Training visualization
additional_cells.append(create_cell("code", [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Training History', fontsize=16)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_title('Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(epochs, history['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
    "    axes[0, 1].plot(epochs, history['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
    "    axes[0, 1].set_title('Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1 Score\n",
    "    axes[1, 0].plot(epochs, history['train_f1'], 'b-', label='Train F1', linewidth=2)\n",
    "    axes[1, 0].plot(epochs, history['val_f1'], 'r-', label='Val F1', linewidth=2)\n",
    "    axes[1, 0].set_title('F1 Score')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('F1 Score')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # AUC\n",
    "    axes[1, 1].plot(epochs, history['val_auc'], 'g-', label='Val AUC', linewidth=2)\n",
    "    axes[1, 1].set_title('AUC Score')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('AUC')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add phase separation line\n",
    "    if phase1_epochs > 0:\n",
    "        for ax in axes.flat:\n",
    "            ax.axvline(x=phase1_epochs, color='orange', linestyle='--', alpha=0.7, label='Phase 2 Start')\n",
    "            if ax == axes[0, 0]:  # Only add legend to first subplot\n",
    "                ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./outputs/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history if we have data\n",
    "if len(history['train_loss']) > 0:\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Print final metrics\n",
    "    print(\"\\nFinal Training Metrics:\")\n",
    "    print(f\"Best Validation Loss: {min(history['val_loss']):.4f}\")\n",
    "    print(f\"Best Validation Accuracy: {max(history['val_acc']):.4f}\")\n",
    "    print(f\"Best Validation F1: {max(history['val_f1']):.4f}\")\n",
    "    print(f\"Best Validation AUC: {max(history['val_auc']):.4f}\")\nelse:\n",
    "    print(\"No training history available. Skipping visualization.\")"
]))

# Model evaluation
additional_cells.append(create_cell("markdown", [
    "## 6Ô∏è‚É£ Model Evaluation\n",
    "\n",
    "Let's evaluate our trained model on the test set and generate comprehensive metrics."
]))

additional_cells.append(create_cell("code", [
    "# Load best model for evaluation\n",
    "try:\n",
    "    checkpoint = torch.load(os.path.join(CONFIG['SAVE_PATH'], 'best_final_model.pth'), map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(\"‚úÖ Loaded best final model for evaluation\")\n",
    "    print(f\"Model was saved at epoch {checkpoint['epoch']} with val loss {checkpoint['val_loss']:.4f}\")\nexcept:\n",
    "    print(\"‚ö†Ô∏è  No saved model found. Using current model state.\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_loss, test_metrics, test_labels, test_preds, test_probs = validate_epoch(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"Test Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Test Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"Test F1: {test_metrics['f1']:.4f}\")\n",
    "print(f\"Test AUC: {test_metrics.get('auc', 0.0):.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=class_names))"
]))

# Confusion matrix and ROC curves
additional_cells.append(create_cell("code", [
    "# Plot confusion matrix and ROC curves\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./outputs/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print normalized confusion matrix\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./outputs/confusion_matrix_normalized.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curves(y_true, y_prob, class_names):\n",
    "    \"\"\"Plot ROC curves for each class\"\"\"\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    \n",
    "    # Binarize labels for multiclass ROC\n",
    "    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
    "    \n",
    "    for i, (class_name, color) in enumerate(zip(class_names, colors)):\n",
    "        if i < y_true_bin.shape[1] and i < len(y_prob[0]):\n",
    "            fpr, tpr, _ = roc_curve(y_true_bin[:, i], [prob[i] for prob in y_prob])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            plt.plot(fpr, tpr, color=color, lw=2,\n",
    "                    label=f'{class_name} (AUC = {roc_auc:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Each Class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./outputs/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Generate plots if we have test results\n",
    "if len(test_labels) > 0:\n",
    "    plot_confusion_matrix(test_labels, test_preds, class_names)\n",
    "    \n",
    "    if len(test_probs) > 0 and len(test_probs[0]) == len(class_names):\n",
    "        plot_roc_curves(test_labels, test_probs, class_names)\n",
    "    else:\n",
    "        print(\"Skipping ROC curves due to insufficient probability data\")\nelse:\n",
    "    print(\"No test results available for plotting.\")"
]))

# Add the remaining cells to the notebook
notebook['cells'].extend(additional_cells)

# Save the updated notebook
with open('/workspace/diabetic_retinopathy_detection.ipynb', 'w') as f:
    json.dump(notebook, f, indent=1)

print("Additional cells added successfully!")