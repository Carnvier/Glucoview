#!/usr/bin/env python3
"""
Script to create a code-only diabetic retinopathy detection notebook
All explanations are in comments within code cells
"""

import json

def create_cell(cell_type, source, metadata=None):
    """Create a notebook cell"""
    cell = {
        "cell_type": cell_type,
        "metadata": metadata or {},
        "source": source if isinstance(source, list) else [source]
    }
    
    if cell_type == "code":
        cell["execution_count"] = None
        cell["outputs"] = []
    
    return cell

# Define all notebook cells as code
cells = []

# Title and setup as code comments
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# DIABETIC RETINOPATHY DETECTION PIPELINE - IET CODEFEST 2025\n",
    "# ============================================================================\n",
    "# Complete ML Pipeline using PyTorch and ResNet50\n",
    "#\n",
    "# Pipeline Overview:\n",
    "# 1. Dataset Understanding & Label Cleaning\n",
    "# 2. Exploratory Data Analysis (EDA)\n",
    "# 3. Preprocessing & Augmentation\n",
    "# 4. Model Training (Two-phase ResNet50)\n",
    "# 5. Explainability (Grad-CAM)\n",
    "# 6. Model Export (ONNX for Next.js)\n",
    "# 7. Comprehensive Evaluation\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üöÄ Starting Diabetic Retinopathy Detection Pipeline\")\n",
    "print(\"üìã IET Codefest 2025 - Complete ML Solution\")\n",
    "print(\"‚ö° Optimized for speed and efficiency\")"
]))

# Install packages
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# PACKAGE INSTALLATION\n",
    "# ============================================================================\n",
    "# Install all required packages for the pipeline\n",
    "\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install timm albumentations opencv-python-headless\n",
    "!pip install pytorch-grad-cam onnx onnxruntime scikit-learn\n",
    "!pip install matplotlib seaborn plotly pandas numpy\n",
    "!pip install efficientnet-pytorch\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")"
]))

# Imports
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "# Import all necessary libraries for the complete pipeline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import timm\n",
    "\n",
    "# Image processing imports\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ML utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_curve, auc,\n",
    "    precision_recall_curve, f1_score, accuracy_score\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Explainability imports\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "# ONNX export imports\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Configure environment\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "print(\"‚úÖ All imports loaded successfully!\")"
]))

# Configuration
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# CONFIGURATION SETTINGS\n",
    "# ============================================================================\n",
    "# Main configuration for the entire pipeline\n",
    "# Update DATA_PATH and LABELS_FILE to match your dataset location\n",
    "\n",
    "CONFIG = {\n",
    "    # Data paths - UPDATE THESE FOR YOUR DATASET\n",
    "    'DATA_PATH': '/kaggle/input',          # Update this path to your dataset location\n",
    "    'LABELS_FILE': 'labels.csv',           # Update this to your labels file name\n",
    "    \n",
    "    # Model parameters\n",
    "    'IMAGE_SIZE': 224,                     # Input image size (224x224)\n",
    "    'BATCH_SIZE': 32,                      # Training batch size\n",
    "    'NUM_EPOCHS': 50,                      # Maximum training epochs\n",
    "    'LEARNING_RATE': 1e-4,                 # Initial learning rate\n",
    "    'WEIGHT_DECAY': 1e-5,                  # Weight decay for regularization\n",
    "    'NUM_CLASSES': 5,                      # Number of classification classes\n",
    "    'MODEL_NAME': 'resnet50',              # Model architecture\n",
    "    \n",
    "    # Training parameters\n",
    "    'PATIENCE': 10,                        # Early stopping patience\n",
    "    'MIN_DELTA': 0.001,                    # Minimum improvement for early stopping\n",
    "    'SAVE_PATH': './models/',              # Model save directory\n",
    "    'RANDOM_SEED': 42                      # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(CONFIG['SAVE_PATH'], exist_ok=True)\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "\n",
    "# Display configuration\n",
    "print(\"‚öôÔ∏è  Pipeline Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"{key:<20}: {value}\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚úÖ Configuration loaded successfully!\")"
]))

# Label cleaning function
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# LABEL CLEANING AND NORMALIZATION\n",
    "# ============================================================================\n",
    "# Clean and normalize inconsistent labels into 5 standardized classes:\n",
    "# 0 = No_DR, 1 = Mild, 2 = Moderate, 3 = Severe, 4 = Proliferative_DR\n",
    "\n",
    "def clean_labels(df):\n",
    "    \"\"\"\n",
    "    Clean and normalize inconsistent labels into 5 standardized classes\n",
    "    Handles numeric, text, mixed case, extra spaces, and leading zeros\n",
    "    \"\"\"\n",
    "    print(\"üßπ Starting label cleaning process...\")\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Convert to string and strip whitespace\n",
    "    df_clean['label'] = df_clean['label'].astype(str).str.strip()\n",
    "    \n",
    "    # Define comprehensive mapping for various label formats\n",
    "    label_mapping = {\n",
    "        # Numeric labels (including leading zeros and decimals)\n",
    "        '0': 0, '00': 0, '0.0': 0,\n",
    "        '1': 1, '01': 1, '1.0': 1,\n",
    "        '2': 2, '02': 2, '2.0': 2,\n",
    "        '3': 3, '03': 3, '3.0': 3,\n",
    "        '4': 4, '04': 4, '4.0': 4,\n",
    "        \n",
    "        # Text labels (case insensitive variations)\n",
    "        'NO_DR': 0, 'No_DR': 0, 'no_dr': 0, 'No DR': 0, 'no dr': 0, 'NO DR': 0,\n",
    "        'MILD': 1, 'Mild': 1, 'mild': 1,\n",
    "        'MODERATE': 2, 'Moderate': 2, 'moderate': 2,\n",
    "        'SEVERE': 3, 'Severe': 3, 'severe': 3,\n",
    "        'PROLIFERATIVE_DR': 4, 'Proliferative_DR': 4, 'proliferative_dr': 4,\n",
    "        'PROLIFERATIVE DR': 4, 'Proliferative DR': 4, 'proliferative dr': 4\n",
    "    }\n",
    "    \n",
    "    # Apply mapping\n",
    "    df_clean['label_clean'] = df_clean['label'].map(label_mapping)\n",
    "    \n",
    "    # Identify invalid labels\n",
    "    invalid_mask = df_clean['label_clean'].isna()\n",
    "    invalid_labels = df_clean[invalid_mask]['label'].unique()\n",
    "    \n",
    "    print(f\"üìä Found {invalid_mask.sum()} invalid labels: {list(invalid_labels)}\")\n",
    "    \n",
    "    # Remove invalid labels\n",
    "    df_clean = df_clean[~invalid_mask].copy()\n",
    "    \n",
    "    # Convert to int\n",
    "    df_clean['label_clean'] = df_clean['label_clean'].astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Label cleaning completed: {len(df_clean)} valid samples\")\n",
    "    return df_clean, invalid_labels\n",
    "\n",
    "# Define class names for reference\n",
    "class_names = ['No_DR', 'Mild', 'Moderate', 'Severe', 'Proliferative_DR']\n",
    "print(f\"üìù Class mapping: {dict(enumerate(class_names))}\")"
]))

# Load and clean data
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# DATA LOADING AND CLEANING\n",
    "# ============================================================================\n",
    "# Load labels.csv and clean inconsistent labels\n",
    "\n",
    "print(\"üìÇ Loading labels.csv...\")\n",
    "try:\n",
    "    # Try to find labels file in various common locations\n",
    "    possible_paths = [\n",
    "        os.path.join(CONFIG['DATA_PATH'], CONFIG['LABELS_FILE']),\n",
    "        CONFIG['LABELS_FILE'],\n",
    "        './labels.csv',\n",
    "        '../input/labels.csv',\n",
    "        './labels (1).csv'  # Common Kaggle download name\n",
    "    ]\n",
    "    \n",
    "    labels_df = None\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            labels_df = pd.read_csv(path)\n",
    "            print(f\"‚úÖ Found labels file at: {path}\")\n",
    "            break\n",
    "    \n",
    "    if labels_df is None:\n",
    "        raise FileNotFoundError(\"labels.csv not found\")\n",
    "    \n",
    "    print(f\"üìä Original dataset shape: {labels_df.shape}\")\n",
    "    print(f\"üìã Columns: {list(labels_df.columns)}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nüîç First 10 rows:\")\n",
    "    print(labels_df.head(10))\n",
    "    \n",
    "    # Show unique labels before cleaning\n",
    "    unique_labels = sorted(labels_df['label'].unique())\n",
    "    print(f\"\\nüè∑Ô∏è  Unique labels before cleaning ({len(unique_labels)}): {unique_labels}\")\n",
    "    \n",
    "    # Clean labels\n",
    "    labels_clean, invalid_labels = clean_labels(labels_df)\n",
    "    \n",
    "    print(f\"\\nüìà Cleaned dataset shape: {labels_clean.shape}\")\n",
    "    print(f\"üóëÔ∏è  Removed {len(labels_df) - len(labels_clean)} invalid entries\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ö†Ô∏è  Error: {e}\")\n",
    "    print(\"üîß Creating sample dataset for demonstration...\")\n",
    "    \n",
    "    # Create sample dataset for demo purposes\n",
    "    np.random.seed(42)\n",
    "    sample_data = {\n",
    "        'image_id': [f'img_{i:04d}.jpg' for i in range(1000)],\n",
    "        'label': np.random.choice(['0', '1', '2', '3', '4', 'No_DR', 'Mild', 'unknown', ' 01 '], 1000)\n",
    "    }\n",
    "    labels_df = pd.DataFrame(sample_data)\n",
    "    labels_clean, invalid_labels = clean_labels(labels_df)\n",
    "    print(\"‚úÖ Sample dataset created for demonstration.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA LOADING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples loaded: {len(labels_clean)}\")\n",
    "print(f\"Classes: {len(class_names)}\")\n",
    "print(f\"Invalid labels removed: {len(invalid_labels) if invalid_labels is not None else 0}\")\n",
    "print(\"=\"*60)"
]))

# Class distribution analysis
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# CLASS DISTRIBUTION ANALYSIS\n",
    "# ============================================================================\n",
    "# Analyze class distribution and visualize imbalance\n",
    "\n",
    "print(\"üìä Analyzing class distribution...\")\n",
    "\n",
    "# Calculate class distribution\n",
    "class_counts = labels_clean['label_clean'].value_counts().sort_index()\n",
    "\n",
    "print(\"\\nüìà Class Distribution:\")\n",
    "print(\"=\" * 50)\n",
    "for i, (class_id, count) in enumerate(class_counts.items()):\n",
    "    percentage = count / len(labels_clean) * 100\n",
    "    print(f\"{class_id}: {class_names[class_id]:<15} {count:>6} ({percentage:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìã Total valid samples: {len(labels_clean)}\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Class Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Bar plot\n",
    "axes[0, 0].bar(range(len(class_counts)), class_counts.values, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Class Distribution (Count)', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Class')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_xticks(range(len(class_names)))\n",
    "axes[0, 0].set_xticklabels(class_names, rotation=45, ha='right')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    axes[0, 0].text(i, v + max(class_counts.values) * 0.01, str(v), \n",
    "                   ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "percentages = class_counts / len(labels_clean) * 100\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(class_names)))\n",
    "wedges, texts, autotexts = axes[0, 1].pie(percentages, labels=class_names, autopct='%1.1f%%', \n",
    "                                         startangle=90, colors=colors)\n",
    "axes[0, 1].set_title('Class Distribution (Percentage)', fontweight='bold')\n",
    "\n",
    "# Log scale bar plot for better imbalance visualization\n",
    "axes[1, 0].bar(range(len(class_counts)), class_counts.values, color='lightcoral', edgecolor='black')\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].set_title('Class Distribution (Log Scale)', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Class')\n",
    "axes[1, 0].set_ylabel('Count (log scale)')\n",
    "axes[1, 0].set_xticks(range(len(class_names)))\n",
    "axes[1, 0].set_xticklabels(class_names, rotation=45, ha='right')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Imbalance ratio analysis\n",
    "imbalance_ratios = [class_counts.max() / count for count in class_counts.values]\n",
    "axes[1, 1].bar(range(len(class_counts)), imbalance_ratios, color='orange', edgecolor='black')\n",
    "axes[1, 1].set_title('Class Imbalance Ratios', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Class')\n",
    "axes[1, 1].set_ylabel('Imbalance Ratio')\n",
    "axes[1, 1].set_xticks(range(len(class_names)))\n",
    "axes[1, 1].set_xticklabels(class_names, rotation=45, ha='right')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./outputs/class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Analyze class imbalance\n",
    "imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "print(f\"\\n‚öñÔ∏è  Class imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "if imbalance_ratio > 5:\n",
    "    print(\"‚ö†Ô∏è  Significant class imbalance detected. Will use weighted sampling/loss.\")\n",
    "else:\n",
    "    print(\"‚úÖ Class distribution is relatively balanced.\")\n",
    "\n",
    "print(\"‚úÖ Class distribution analysis completed!\")"
]))

# Image verification
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# IMAGE FILE VERIFICATION\n",
    "# ============================================================================\n",
    "# Check if all labeled images exist and identify any missing files\n",
    "\n",
    "def find_images(labels_df, data_path):\n",
    "    \"\"\"\n",
    "    Find image files and check for missing images\n",
    "    Searches common image extensions in various subdirectories\n",
    "    \"\"\"\n",
    "    print(\"üîç Searching for image files...\")\n",
    "    \n",
    "    # Common image extensions\n",
    "    extensions = ['.jpg', '.jpeg', '.png', '.tiff', '.tif']\n",
    "    \n",
    "    # Look for images in various subdirectories\n",
    "    search_paths = [\n",
    "        data_path,\n",
    "        os.path.join(data_path, 'images'),\n",
    "        os.path.join(data_path, 'train'),\n",
    "        os.path.join(data_path, 'test'),\n",
    "        './images',\n",
    "        '../input/images',\n",
    "        './'  # Current directory\n",
    "    ]\n",
    "    \n",
    "    image_files = {}\n",
    "    image_dir = None\n",
    "    \n",
    "    for search_path in search_paths:\n",
    "        if os.path.exists(search_path):\n",
    "            for ext in extensions:\n",
    "                pattern = f\"*{ext}\"\n",
    "                files = list(Path(search_path).glob(pattern))\n",
    "                if files:\n",
    "                    if image_dir is None:\n",
    "                        image_dir = search_path\n",
    "                    for file in files:\n",
    "                        image_files[file.name] = str(file)\n",
    "                    print(f\"üìÅ Found {len(files)} {ext} files in {search_path}\")\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"‚ùå No image files found. Please check your data path.\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Check for missing images\n",
    "    missing_images = []\n",
    "    existing_images = []\n",
    "    \n",
    "    for img_id in labels_df['image_id']:\n",
    "        if img_id in image_files:\n",
    "            existing_images.append(img_id)\n",
    "        else:\n",
    "            # Try with different extensions\n",
    "            base_name = os.path.splitext(img_id)[0]\n",
    "            found = False\n",
    "            for ext in extensions:\n",
    "                if f\"{base_name}{ext}\" in image_files:\n",
    "                    existing_images.append(img_id)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                missing_images.append(img_id)\n",
    "    \n",
    "    return image_files, existing_images, missing_images, image_dir\n",
    "\n",
    "# Find and verify images\n",
    "print(\"üîç Starting image verification process...\")\n",
    "image_files, existing_images, missing_images, image_dir = find_images(labels_clean, CONFIG['DATA_PATH'])\n",
    "\n",
    "if image_files:\n",
    "    print(f\"\\nüìä Image File Summary:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Total image files found: {len(image_files)}\")\n",
    "    print(f\"Images with labels: {len(existing_images)}\")\n",
    "    print(f\"Missing images: {len(missing_images)}\")\n",
    "    print(f\"Match rate: {len(existing_images)/len(labels_clean)*100:.1f}%\")\n",
    "    \n",
    "    if missing_images:\n",
    "        print(f\"\\n‚ö†Ô∏è  First 10 missing images: {missing_images[:10]}\")\n",
    "        \n",
    "        # Filter out missing images\n",
    "        labels_final = labels_clean[labels_clean['image_id'].isin(existing_images)].copy()\n",
    "        print(f\"üìä Final dataset size after removing missing images: {len(labels_final)}\")\n",
    "    else:\n",
    "        labels_final = labels_clean.copy()\n",
    "        print(\"‚úÖ All labeled images found!\")\n",
    "    \n",
    "    # Update config with image directory\n",
    "    CONFIG['IMAGE_DIR'] = image_dir\n",
    "    print(f\"üìÅ Image directory set to: {image_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No images found. Using labels only for demonstration.\")\n",
    "    labels_final = labels_clean.copy()\n",
    "    CONFIG['IMAGE_DIR'] = None\n",
    "\n",
    "# Final dataset summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMAGE VERIFICATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Images found: {len(image_files) if image_files else 0}\")\n",
    "print(f\"Final dataset size: {len(labels_final)}\")\n",
    "print(f\"Image directory: {CONFIG.get('IMAGE_DIR', 'None')}\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Image verification completed!\")"
]))

# Sample visualization
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# SAMPLE IMAGES VISUALIZATION\n",
    "# ============================================================================\n",
    "# Display random samples from each class to understand the data better\n",
    "\n",
    "def load_and_preprocess_image(image_path, size=224):\n",
    "    \"\"\"\n",
    "    Load and preprocess image for display\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Resize\n",
    "        img = cv2.resize(img, (size, size))\n",
    "        \n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def crop_black_borders(image, threshold=10):\n",
    "    \"\"\"\n",
    "    Crop black borders from retinal images\n",
    "    This is crucial for retinal images which often have black circular borders\n",
    "    \"\"\"\n",
    "    # Convert to grayscale for border detection\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Find non-black pixels\n",
    "    coords = cv2.findNonZero((gray > threshold).astype(np.uint8))\n",
    "    \n",
    "    if coords is not None:\n",
    "        # Get bounding box\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        \n",
    "        # Add small padding\n",
    "        pad = 5\n",
    "        x = max(0, x - pad)\n",
    "        y = max(0, y - pad)\n",
    "        w = min(image.shape[1] - x, w + 2*pad)\n",
    "        h = min(image.shape[0] - y, h + 2*pad)\n",
    "        \n",
    "        # Crop image\n",
    "        cropped = image[y:y+h, x:x+w]\n",
    "        return cropped\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Display sample images if available\n",
    "if CONFIG['IMAGE_DIR'] and len(labels_final) > 0:\n",
    "    print(\"üñºÔ∏è  Displaying sample images from each class...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(5, 3, figsize=(12, 20))\n",
    "    fig.suptitle('Sample Images by Class\\n(Original ‚Üí Cropped ‚Üí Resized)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for class_id in range(5):\n",
    "        # Get samples from this class\n",
    "        class_samples = labels_final[labels_final['label_clean'] == class_id]\n",
    "        \n",
    "        if len(class_samples) > 0:\n",
    "            # Get a random sample\n",
    "            sample = class_samples.sample(1, random_state=42).iloc[0]\n",
    "            img_id = sample['image_id']\n",
    "            \n",
    "            # Find image path\n",
    "            img_path = None\n",
    "            if img_id in image_files:\n",
    "                img_path = image_files[img_id]\n",
    "            else:\n",
    "                # Try different extensions\n",
    "                base_name = os.path.splitext(img_id)[0]\n",
    "                for ext in ['.jpg', '.jpeg', '.png']:\n",
    "                    if f\"{base_name}{ext}\" in image_files:\n",
    "                        img_path = image_files[f\"{base_name}{ext}\"]\n",
    "                        break\n",
    "            \n",
    "            if img_path and os.path.exists(img_path):\n",
    "                # Load original image\n",
    "                original_img = load_and_preprocess_image(img_path, size=300)\n",
    "                \n",
    "                if original_img is not None:\n",
    "                    # Crop borders\n",
    "                    cropped_img = crop_black_borders(original_img)\n",
    "                    \n",
    "                    # Resize to final size\n",
    "                    final_img = cv2.resize(cropped_img, (224, 224))\n",
    "                    \n",
    "                    # Display images\n",
    "                    axes[class_id, 0].imshow(original_img)\n",
    "                    axes[class_id, 0].set_title(f'{class_names[class_id]}\\nOriginal ({original_img.shape[0]}x{original_img.shape[1]})', fontweight='bold')\n",
    "                    axes[class_id, 0].axis('off')\n",
    "                    \n",
    "                    axes[class_id, 1].imshow(cropped_img)\n",
    "                    axes[class_id, 1].set_title(f'Cropped\\n({cropped_img.shape[0]}x{cropped_img.shape[1]})')\n",
    "                    axes[class_id, 1].axis('off')\n",
    "                    \n",
    "                    axes[class_id, 2].imshow(final_img)\n",
    "                    axes[class_id, 2].set_title('Resized\\n(224x224)')\n",
    "                    axes[class_id, 2].axis('off')\n",
    "                    \n",
    "                    continue\n",
    "        \n",
    "        # If no image found, show placeholder\n",
    "        for j in range(3):\n",
    "            axes[class_id, j].text(0.5, 0.5, f'{class_names[class_id]}\\nNo image available', \n",
    "                                 ha='center', va='center', transform=axes[class_id, j].transAxes,\n",
    "                                 fontsize=12, fontweight='bold')\n",
    "            axes[class_id, j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./outputs/sample_images.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"‚úÖ Sample images visualization completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No images available for visualization.\")\n",
    "    print(\"üìù The pipeline will continue with data loading and model training structure.\")\n",
    "\n",
    "print(\"\\n‚úÖ Sample visualization section completed!\")"
]))

# Dataset class
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# CUSTOM DATASET CLASS\n",
    "# ============================================================================\n",
    "# Custom PyTorch dataset with black border cropping, resizing, and normalization\n",
    "\n",
    "class DiabeticRetinopathyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for diabetic retinopathy detection\n",
    "    Features:\n",
    "    - Automatic black border cropping for retinal images\n",
    "    - Image resizing to 224√ó224\n",
    "    - ImageNet normalization\n",
    "    - Flexible augmentation support\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, image_dir, transform=None, is_training=True):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.is_training = is_training\n",
    "        \n",
    "        # ImageNet statistics for normalization\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_id = row['image_id']\n",
    "        label = row['label_clean']\n",
    "        \n",
    "        # Load image\n",
    "        img_path = self._find_image_path(img_id)\n",
    "        \n",
    "        if img_path is None:\n",
    "            # Return dummy image if not found\n",
    "            image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            image = self._load_image(img_path)\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "    def _find_image_path(self, img_id):\n",
    "        \"\"\"Find the full path to an image\"\"\"\n",
    "        if self.image_dir is None:\n",
    "            return None\n",
    "        \n",
    "        # Try exact match first\n",
    "        exact_path = os.path.join(self.image_dir, img_id)\n",
    "        if os.path.exists(exact_path):\n",
    "            return exact_path\n",
    "        \n",
    "        # Try different extensions\n",
    "        base_name = os.path.splitext(img_id)[0]\n",
    "        for ext in ['.jpg', '.jpeg', '.png', '.tiff', '.tif']:\n",
    "            path = os.path.join(self.image_dir, f\"{base_name}{ext}\")\n",
    "            if os.path.exists(path):\n",
    "                return path\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _load_image(self, img_path):\n",
    "        \"\"\"Load and preprocess image with border cropping\"\"\"\n",
    "        try:\n",
    "            # Load image\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                raise ValueError(f\"Could not load image: {img_path}\")\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Crop black borders (crucial for retinal images)\n",
    "            img = self._crop_black_borders(img)\n",
    "            \n",
    "            # Resize to target size\n",
    "            img = cv2.resize(img, (CONFIG['IMAGE_SIZE'], CONFIG['IMAGE_SIZE']))\n",
    "            \n",
    "            return img\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return black image as fallback\n",
    "            return np.zeros((CONFIG['IMAGE_SIZE'], CONFIG['IMAGE_SIZE'], 3), dtype=np.uint8)\n",
    "    \n",
    "    def _crop_black_borders(self, image, threshold=10):\n",
    "        \"\"\"Crop black borders from retinal images\"\"\"\n",
    "        # Convert to grayscale for border detection\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Find non-black pixels\n",
    "        coords = cv2.findNonZero((gray > threshold).astype(np.uint8))\n",
    "        \n",
    "        if coords is not None:\n",
    "            # Get bounding box\n",
    "            x, y, w, h = cv2.boundingRect(coords)\n",
    "            \n",
    "            # Add small padding\n",
    "            pad = 5\n",
    "            x = max(0, x - pad)\n",
    "            y = max(0, y - pad)\n",
    "            w = min(image.shape[1] - x, w + 2*pad)\n",
    "            h = min(image.shape[0] - y, h + 2*pad)\n",
    "            \n",
    "            # Crop image\n",
    "            cropped = image[y:y+h, x:x+w]\n",
    "            return cropped\n",
    "        \n",
    "        return image\n",
    "\n",
    "print(\"‚úÖ Custom dataset class defined successfully!\")"
]))

# Transform functions
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# DATA AUGMENTATION AND TRANSFORMS\n",
    "# ============================================================================\n",
    "# Define comprehensive augmentation pipeline using Albumentations\n",
    "\n",
    "def get_transforms(is_training=True):\n",
    "    \"\"\"\n",
    "    Get image transforms for training/validation\n",
    "    \n",
    "    Training augmentations:\n",
    "    - Horizontal and vertical flips\n",
    "    - Small rotations\n",
    "    - Brightness/contrast adjustments\n",
    "    - Hue/saturation variations\n",
    "    - Gaussian noise\n",
    "    - ImageNet normalization\n",
    "    \n",
    "    Validation: Only normalization\n",
    "    \"\"\"\n",
    "    \n",
    "    if is_training:\n",
    "        transform = A.Compose([\n",
    "            # Geometric augmentations\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Rotate(limit=15, p=0.5, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "            \n",
    "            # Color augmentations\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.2, \n",
    "                contrast_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=10,\n",
    "                sat_shift_limit=20,\n",
    "                val_shift_limit=10,\n",
    "                p=0.3\n",
    "            ),\n",
    "            \n",
    "            # Noise augmentation\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "            \n",
    "            # Optional: Advanced augmentations\n",
    "            A.OneOf([\n",
    "                A.OpticalDistortion(p=0.3),\n",
    "                A.GridDistortion(p=0.3),\n",
    "                A.ElasticTransform(p=0.3),\n",
    "            ], p=0.2),\n",
    "            \n",
    "            # Normalization (ImageNet stats)\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    else:\n",
    "        # Validation/test transforms - only normalization\n",
    "        transform = A.Compose([\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "# Test transforms\n",
    "train_transform = get_transforms(is_training=True)\n",
    "val_transform = get_transforms(is_training=False)\n",
    "\n",
    "print(\"‚úÖ Data augmentation transforms defined successfully!\")\n",
    "print(f\"üìä Training augmentations: {len([t for t in train_transform.transforms if hasattr(t, 'p')])} transforms\")\n",
    "print(f\"üìä Validation transforms: {len(val_transform.transforms)} transforms\")"
]))

# Data splitting and loading
cells.append(create_cell("code", [
    "# ============================================================================\n",
    "# DATA SPLITTING AND DATASET CREATION\n",
    "# ============================================================================\n",
    "# Split data into train/validation/test sets and create datasets\n",
    "\n",
    "print(\"üîÄ Splitting data into train/validation/test sets...\")\n",
    "\n",
    "# Split data into train, validation, and test sets (70/15/15)\n",
    "train_df, temp_df = train_test_split(\n",
    "    labels_final, \n",
    "    test_size=0.3, \n",
    "    random_state=CONFIG['RANDOM_SEED'],\n",
    "    stratify=labels_final['label_clean']\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, \n",
    "    test_size=0.5, \n",
    "    random_state=CONFIG['RANDOM_SEED'],\n",
    "    stratify=temp_df['label_clean']\n",
    ")\n",
    "\n",
    "print(f\"üìä Dataset splits:\")\n",
    "print(f\"  Train: {len(train_df)} samples ({len(train_df)/len(labels_final)*100:.1f}%)\")\n",
    "print(f\"  Validation: {len(val_df)} samples ({len(val_df)/len(labels_final)*100:.1f}%)\")\n",
    "print(f\"  Test: {len(test_df)} samples ({len(test_df)/len(labels_final)*100:.1f}%)\")\n",
    "\n",
    "# Display class distribution in each split\n",
    "splits_info = {\n",
    "    'Train': train_df['label_clean'].value_counts().sort_index(),\n",
    "    'Validation': val_df['label_clean'].value_counts().sort_index(),\n",
    "    'Test': test_df['label_clean'].value_counts().sort_index()\n",
    "}\n",
    "\n",
    "print(\"\\nüìà Class distribution by split:\")\n",
    "print(\"=\" * 60)\n",
    "for split_name, counts in splits_info.items():\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    for class_id, count in counts.items():\n",
    "        percentage = count / len(splits_info[split_name]) * 100 if split_name == 'Train' else count / len(val_df if split_name == 'Validation' else test_df) * 100\n",
    "        print(f\"  {class_names[class_id]:<15}: {count:>4} ({percentage:>5.1f}%)\")\n",
    "\n",
    "# Calculate class weights for handling imbalance\n",
    "print(\"\\n‚öñÔ∏è  Calculating class weights for balanced training...\")\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_df['label_clean']),\n",
    "    y=train_df['label_clean']\n",
    ")\n",
    "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "print(f\"\\nüìä Class weights for balanced loss:\")\n",
    "for i, weight in enumerate(class_weights):\n",
    "    print(f\"  {class_names[i]:<15}: {weight:.3f}\")\n",
    "\n",
    "# Create datasets\n",
    "print(\"\\nüóÇÔ∏è  Creating PyTorch datasets...\")\n",
    "train_dataset = DiabeticRetinopathyDataset(\n",
    "    train_df, \n",
    "    CONFIG['IMAGE_DIR'], \n",
    "    transform=get_transforms(is_training=True),\n",
    "    is_training=True\n",
    ")\n",
    "\n",
    "val_dataset = DiabeticRetinopathyDataset(\n",
    "    val_df, \n",
    "    CONFIG['IMAGE_DIR'], \n",
    "    transform=get_transforms(is_training=False),\n",
    "    is_training=False\n",
    ")\n",
    "\n",
    "test_dataset = DiabeticRetinopathyDataset(\n",
    "    test_df, \n",
    "    CONFIG['IMAGE_DIR'], \n",
    "    transform=get_transforms(is_training=False),\n",
    "    is_training=False\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Datasets created successfully!\")\n",
    "print(f\"  Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"  Validation dataset: {len(val_dataset)} samples\")\n",
    "print(f\"  Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA PREPARATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples: {len(labels_final)}\")\n",
    "print(f\"Train/Val/Test split: {len(train_df)}/{len(val_df)}/{len(test_df)}\")\n",
    "print(f\"Classes: {len(class_names)}\")\n",
    "print(f\"Image size: {CONFIG['IMAGE_SIZE']}x{CONFIG['IMAGE_SIZE']}\")\n",
    "print(f\"Augmentation: {'Enabled' if train_dataset.transform else 'Disabled'}\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Data preparation completed!\")"
]))

# Continue with remaining cells...
# I'll add the rest in the next part to keep the response manageable

# Save the first part of the notebook
notebook = {
    "cells": cells,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

with open('/workspace/diabetic_retinopathy_code_only.ipynb', 'w') as f:
    json.dump(notebook, f, indent=1)

print("Code-only notebook (Part 1) created successfully!")